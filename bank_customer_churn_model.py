# -*- coding: utf-8 -*-
"""Bank_customer_churn_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c3FC1ztZjgeYKrssdRqmB_bXze6AYhdw

**BANK CUSTOMER CHURN MODEL**

**Objectives**



1.   Data Encoding
2.   Feature Scaling
3.   Handling Imbalance Data
4.   Support Vector Machine Classifier
5.   Grid Search For Hyperparameter Tunning

**Import Library**
"""

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

"""**Import Data**"""

df = pd.read_csv('https://github.com/YBIFoundation/Dataset/raw/main/Bank%20Churn%20Modelling.csv')

df.head()

"""**Describe Data**"""

df.info()

df.duplicated('CustomerId').sum()

df = df.set_index('CustomerId')

df.info()

"""**Data Visualization**"""

sns.countplot(x='Geography', data=df)
plt.title('Distribution of Customers by Geography')
plt.show()

sns.countplot(x='Gender', data=df)
plt.title('Distribution of Customers by Gender')
plt.show()

sns.countplot(x='Has Credit Card', data=df)
plt.title('Distribution of Credit Card Holders')
plt.show()

sns.countplot(x='Is Active Member', data=df)
plt.title('Distribution of Active Members')
plt.show()

sns.countplot(x='Churn', data=df)
plt.title('Customer Churn Distribution')
plt.show()

sns.countplot(x='Zero Balance', data=df)
plt.title('Distribution of Zero Balance Accounts')
plt.show()

corr_matrix = df.select_dtypes(include=[np.number]).corr()  # Select only numerical columns
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

sns.boxplot(x='Geography', y='Balance', data=df)
plt.title('Balance by Geography')
plt.show()

"""**Encoding**"""

df['Geography'].value_counts()

df.replace({'Geography':{'France':2,'Germany':1,'Spain':0}},inplace=True)

df['Gender'].value_counts()

df.replace({'Gender':{'Male':0,'Female':1}},inplace=True)

df['Num Of Products'].value_counts()

df.replace({'Num Of Products':{1:0,2:1,3:1,4:1}},inplace=True)

df['Has Credit Card'].value_counts()

df['Is Active Member'].value_counts()

df.loc[(df['Balance']==0),'Churn'].value_counts()

df['Zero Balance']= np.where(df['Balance']>0,1,0)

df['Zero Balance'].hist()

df.groupby(['Churn','Geography']).count()

"""**Define Target Variable (y) and Feature Variable X**"""

df.columns

X = df.drop(['Surname','Churn'],axis=1)

y = df['Churn']

X.shape

y.shape

from imblearn.under_sampling import RandomUnderSampler

sns.countplot(x='Churn',data=df);

"""**Handling Imbalance Data**


1.   UnderSampling
2.   Over Sampling

**Random UnderSampling**
"""

rus = RandomUnderSampler(random_state=2529)

X_rus,y_rus= rus.fit_resample(X,y)

X_rus.shape,y_rus.shape,X.shape,y.shape

y.value_counts()

y_rus.value_counts()

y_rus.plot(kind = 'hist')

"""**Random Over Sampling**"""

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state= 2529)

X_ros,y_ros = ros.fit_resample(X,y)

X_ros.shape,y_ros.shape,X.shape,y.shape

y.value_counts()

y_ros.plot(kind ='hist')

"""**Train Test Split**"""

from sklearn.model_selection import train_test_split

"""**Split Original Data**"""

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=25)

"""**Split Random Under Sample Data**"""

X_train_ros,X_test_ros,y_train_ros,y_test_ros = train_test_split(X_ros,y_ros,test_size=0.3,random_state=25)

"""**Split Random Over Sample Data**"""

X_train_rus,X_test_rus,y_train_rus,y_test_rus = train_test_split(X_rus,y_rus,test_size=0.3,random_state=25)

"""**Standardize Features**"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

"""**Standardize Original Data**"""

X_train[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_train[['CreditScore','Age','Tenure','Balance','Estimated Salary']])

X_test[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_test[['CreditScore','Age','Tenure','Balance','Estimated Salary']])

"""**Standardize Random Over Sample Data**"""

X_train_ros[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_train_ros[['CreditScore','Age','Tenure','Balance','Estimated Salary']])

X_test_ros[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_test_ros[['CreditScore','Age','Tenure','Balance','Estimated Salary']])

"""**Standardize Random Under Sample Data**"""

X_train_rus[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_train_rus[['CreditScore','Age','Tenure','Balance','Estimated Salary']])

X_test_rus[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_test_rus[['CreditScore','Age','Tenure','Balance','Estimated Salary']])

"""**Support Vector Machine Classifier**"""

from sklearn.svm import SVC

svc = SVC()

svc.fit(X_train,y_train)

y_pred = svc.predict(X_test)

"""**Model Accuracy**"""

from sklearn.metrics import confusion_matrix,classification_report

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

"""**Hyperparameter Tunning**"""

from sklearn.model_selection import GridSearchCV

param_grid = {'C':[0.1,1,10],
              'gamma':[1,0.1,0.01],
              'kernel':['rbf'],
              'class_weight':['balanced']}

grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2,cv=2)
grid.fit(X_train,y_train)

print(grid.best_estimator_)

grid_predictions = grid.predict(X_test)

confusion_matrix(y_test,grid_predictions)

print(classification_report(y_test,grid_predictions))

"""**Hyperparameter Tunning (Random Under Sample Data)**"""

svc_rus = SVC()

svc_rus.fit(X_train_rus,y_train_rus)

y_pred_rus = svc_rus.predict(X_test_rus)

confusion_matrix(y_test_rus,y_pred_rus)

print(classification_report(y_test_rus,y_pred_rus))

param_grid = {'C':[0.1,1,10],
              'gamma':[1,0.1,0.01],
              'kernel':['rbf'],
              'class_weight':['balanced']}

grid_rus = GridSearchCV(SVC(),param_grid,refit=True,verbose=2,cv=2)
grid_rus.fit(X_train_rus,y_train_rus)

print(grid_rus.best_estimator_)

grid_predictions_rus = grid_rus.predict(X_test_rus)

confusion_matrix(y_test_rus,grid_predictions_rus)

print(classification_report(y_test_rus,grid_predictions_rus))

"""**Hyperparameter Tunning (Random Over Sampled Data)**"""

svc_ros = SVC()

svc_ros.fit(X_train_ros,y_train_ros)

y_pred_ros = svc_ros.predict(X_test_ros)

confusion_matrix(y_test_ros,y_pred_ros)

print(classification_report(y_test_ros,y_pred_ros))

param_grid = {'C':[0.1,1,10],
              'gamma':[1,0.1,0.01],
              'kernel':['rbf'],
              'class_weight':['balanced']}

grid_ros = GridSearchCV(SVC(),param_grid,refit=True,verbose=2,cv=2)
grid_ros.fit(X_train_ros,y_train_ros)

print(grid_ros.best_estimator_)

grid_predictions_ros = grid_ros.predict(X_test_ros)

confusion_matrix(y_test_ros,grid_predictions_ros)

print(classification_report(y_test_ros,grid_predictions_ros))

"""**Summary**"""

print(classification_report(y_test,y_pred))

print(classification_report(y_test,grid_predictions))

print(classification_report(y_test_rus,y_pred_rus))

print(classification_report(y_test_rus,grid_predictions_rus))

print(classification_report(y_test_ros,y_pred_ros))

print(classification_report(y_test_ros,grid_predictions_ros))

"""**Explanation**

**Introduction**

Brief overview of customer churn in the banking industry

Importance of predicting customer churn for business

Problem statement: Build a model to predict customer churn based on given data

**Data** **Understanding**

Brief description of the dataset (columns, data types, size)

Exploratory Data Analysis (EDA) insights:

  Distribution of target variable (churn)

  Correlation between features

  Visualization of key features (e.g., histograms, box plots)

**Data** **Preprocessing**

Data Encoding:

Explain the need for encoding categorical features

Describe the encoding technique used (e.g., One-Hot Encoding, Label Encoding)

Justify the choice of encoding method based on the data
Feature Scaling:

Importance of feature scaling for SVM

Explain the scaling technique used (e.g., Standardization, Normalization)

Impact of scaling on model performance

**Handling** **Imbalanced** **Data**

Explain the problem of imbalanced data in churn prediction

Discuss the chosen technique to handle imbalance (e.g., oversampling, undersampling, class weighting)

Justify the selection of the technique based on data characteristics
Model Building: Support Vector Machine (SVM)

Introduction to SVM as a classification algorithm

Explain the concept of support vectors and decision boundary

Advantages of SVM for classification tasks

Parameter tuning using grid search (covered in next section)

**Hyperparameter** **Tuning**

Importance of hyperparameter tuning for model performance

Explain the concept of grid search

Describe the hyperparameters tuned (e.g., C, kernel, gamma)

Evaluation metrics used (e.g., accuracy, precision, recall, F1-score)

**Model** **Evaluation**

Evaluation metrics used to assess model performance

Confusion matrix analysis

ROC curve and AUC

Model performance comparison with other models (optional)

**Conclusion**

Summarize the key findings of the project

Discuss the model's performance and potential improvements

Highlight the impact of the model on business decisions
"""